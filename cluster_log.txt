# first attempt at a script using hard-coded parameters and file paths.
# 10000 iterations (with setting to exit if no change for 1000)
# Logging every 20 iterations (a little too frequent) - logfile of best score and a set of factors (500 files)
# On HYDRA
module load libs/bioconductor/2.14/gcc-4.4.7+R-3.1.1
cd $SCRATCH/seqPredict
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N auto10k -b y -pe smp.pe 2 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/predictFromSequence.autoRun.R

# another run using 5 layers instead of one.  #layer 1 is still the target.layer. May just see dilution of signal and slowing of progression
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N Layer5_10k -b y -pe smp.pe 2 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/predictFromSequence.autoRun.5_layer.R


#  awk '{ if($1 == "chr7" && $3 == "transcript") print $0 }' /mnt/genome-shared-data/bcf/genomeIndexes/hg19_GRCh37_random_chrM/annotation/gencode.v19.annotation.gtf > data/hg19.G19.chr7.transcript.gtf
#qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N Layer5_chr7 -b y -pe smp.pe 8 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/predictFromSequence.chr7.R
# failed with core dump "memory not mapped"
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N Layer5_chr7 -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/predictFromSequence.chr7.R

# I added verbose as a parameter to several functions to get more detailed output.
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N Lay5_chr7v -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/predictFromSequence.chr7.verbose.R

# I also re-wrote modifyLayerByBindingFactor.multiHits() to use IRanges and speed up the layer modification, but it didn't make much difference.
# Kept failing even with 16 cores. No error messages despite using try()
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N Lay5_chr7v -b y -pe smp.pe 32 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/predictFromSequence.chr7.verbose.R

# let's try a smaller chromosome
awk '{ if($1 == "chr22" && $3 == "transcript") print $0 }' /mnt/genome-shared-data/bcf/genomeIndexes/hg19_GRCh37_random_chrM/annotation/gencode.v19.annotation.gtf > data/hg19.G19.chr22.transcript.gtf
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N Lay5_chr22v -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/predictFromSequence.chr22.verbose.R


module load libs/bioconductor/2.14/gcc-4.4.7+R-3.1.1
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N Lay5_chr22v -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr22.verbose.R
# I terminated the above job after 500 iters without improvement (4%)
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N Lay5_chr22.1kb -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr22.1kb.verbose.R


# get chrM transcripts for testing
#awk '{ if($1 == "chrM" && $3 == "transcript") print $0 }' /mnt/genome-shared-data/bcf/genomeIndexes/hg19_GRCh37_random_chrM/annotation/gencode.v19.annotation.gtf > data/hg19.G19.chrM.transcript.gtf

# attempt a parallel job:-
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N L5_chr22.par -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr22.1kb.par.R
#  a chr7 job to see how things have improved
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N L5_chr7.par -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr7.1kb.par.R


# create a chr19 job to test new runLayerBinding.
awk '{ if($1 == "chr19" && $3 == "transcript") print $0 }' /mnt/genome-shared-data/bcf/genomeIndexes/hg19_GRCh37_random_chrM/annotation/gencode.v19.annotation.gtf > data/hg19.G19.chr19.transcript.gtf
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N L5_chr19.par -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr19.1kb.par.R
# and another for smaller regions.
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N L5_chr19.400 -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr19.400bp.par.R

# repeat with chr22, incorporate new scoring measures
#qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N L5_chr22.400 -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr22.400bp.par.R

# renamed the script to test different score methods.
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N L5_c22.acc.400 -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr22.400bp.acc.R

# attempting to redirect STDOUT and STDERR to results folder.
# results/pfs_layer5_chr22_400bp_acc
# ppv (precision) favours getting postive hits.
mkdir results/pfs_layer5_chr22_400bp_ppv
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -o $SCRATCH/seqPredict/results/pfs_layer5_chr22_400bp_ppv -e $SCRATCH/seqPredict/results/pfs_layer5_chr22_400bp_ppv -V -N L5_c22.ppv.400 -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr22.400bp.ppv.R


# try tpr (sensitivity or recall) to maximise hits coming back. Predict will mark a lot of the chrom
mkdir results/pfs_layer5_chr22_400bp_tpr
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -o $SCRATCH/seqPredict/results/pfs_layer5_chr22_400bp_tpr -e $SCRATCH/seqPredict/results/pfs_layer5_chr22_400bp_tpr -V -N L5_c22.tpr.400 -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr22.400bp.tpr.R

# test the behaviour of the acc method with new mutation types and mutable number of factors in factorSet.
mkdir results/pfs_layer5_chr22_400bp_mutTest
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -o $SCRATCH/seqPredict/results/pfs_layer5_chr22_400bp_mutTest -e $SCRATCH/seqPredict/results/pfs_layer5_chr22_400bp_mutTest -V -N L5_c22.mutTest.400 -b y -pe smp.pe 16 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr22.400bp.mutTest.R

# cluster jam so qsub with 8 cores (also upped the max.factors to 200
mkdir results/pfs_layer5_chr22_400bp_mutTest_200bf
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -o $SCRATCH/seqPredict/results/pfs_layer5_chr22_400bp_mutTest_200bf -e $SCRATCH/seqPredict/results/pfs_layer5_chr22_400bp_mutTest_200bf -V -N L5_c22.mutTest.200bf -b y -pe smp.pe 8 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr22.400bp.mutTest.200bf.R

# try chr19 again, higher density of TSS
mkdir results/pfs_layer5_chr19_400bp_mutTest_200bf
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -o $SCRATCH/seqPredict/results/pfs_layer5_chr19_400bp_mutTest_200bf -e $SCRATCH/seqPredict/results/pfs_layer5_chr19_400bp_mutTest_200bf -V -N L5_c19.mutTest.200bf -b y -pe smp.pe 8 Rscript $SCRATCH/seqPredict/predictfromsequence/scripts/pfs.chr19.400bp.mutTest.200bf.R


# On DPSF




 module load libs/bioconductor/3.3/gcc-4.8.5+R-3.3.1

 in R

 source("https://bioconductor.org/biocLite.R")
biocLite("BSgenome.Hsapiens.UCSC.hg19")


	mkdir data
	mkdir results


need to create TSS file for chrom1 (or load whole gtf?)



qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N Lay5_chr22.1kb -b y -pe smp.pe 16 Rscript $SCRATCH/predictfromsequence/scripts/dpsf.pfs.chr22.1kb.verbose.R

awk '{ if($1 == "chr1" && $3 == "transcript") print $0 }' /mnt/data-sets/bcf/genomeIndexes/hg19_GRCh37_random_chrM/annotation/gencode.v19.annotation.gtf > data/hg19.G19.chr1.transcript.gtf

qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N Lay5_chr1.1kb -b y -pe smp.pe 16 Rscript $SCRATCH/predictfromsequence/scripts/dpsf.pfs.chr1.1kb.verbose.R
qsub -cwd -m e -M david.gerrard@manchester.ac.uk -V -N Lay5_chr1.S -b y -pe smp.pe 16 Rscript $SCRATCH/predictfromsequence/scripts/dpsf.pfs.chr1.1kb.verbose.sparse.R

# to check times of each iteration:
 grep 'runLayerBinding pos' ../q_out/Lay5_chr22.1kb.o19381 |wc


# run a vmatchPattern on whole human genome (fails on my desktop)  :  tf.hits <- vmatchPattern("TTTCCCTAATC", genome, fixed=F)
qsub -cwd -m e  -V -N hg19.vMatch -b y -pe smp.pe 16 Rscript $SCRATCH/predictfromsequence/scripts/testGenomePatternMatch.R

# it worked, but used 22Gb of RAM at one point.


Test if script called by batch will work.

	module load libs/bioconductor/3.3/gcc-4.8.5+R-3.3.1
	qsub -cwd -V -N BachOptTest -b y  Rscript $SCRATCH/predictfromsequence/scripts/mus.x-inactivationModel.BatchOpt.fromConfig.R --config scripts/CONFIG.mus.x-inactivationModel.BatchOpt.2016-11-11.dpsf.R --job_id 9999


Then call this file N number of times using SGE_TASK_ID

#!/bin/bash

SCRIPT_TO_RUN=$SCRATCH/predictfromsequence/scripts/mus.x-inactivationModel.BatchOpt.fromConfig.R

CONFIG_FILE=$SCRATCH/predictfromsequence/scripts/CONFIG.mus.x-inactivationModel.BatchOpt.2016-11-11.dpsf.R

# The following line specifies that there are 100 jobs
#$ -t 1-100

# Each time a job is submitted the environment variable SGE_TASK_ID is incremented so to get the nth line of

# The command line to run
Rscript $SCRIPT_TO_RUN --config $CONFIG_FILE --job_id $SGE_TASK_ID


# END OF SCRIPT



qsub -V -cwd ./scripts/mus.x.batchOpt.2016-11-11.submitter.sh

# the 2016-11-11 job had a stupid piece of code that would delete the final results!  managed to stop it after about 30-40 or 100 runs had completed. Partial results
# RE-ran (with code fixed):-
qsub -V -cwd ./scripts/mus.x.batchOpt.2016-11-14.submitter.sh
# as before, large difference in run-speed between parts of batch job. ~70 jobs were at optimisation round 30 before job_ids 14-39 (25 jobs) had logged one round.


# meanwhile, start to collate previous results
qsub -b y -V -cwd -N collate Rscript scripts/collateRunFinalParameters.2016-11-11.R     # loads each final result file and extract best achieved parameters and score.



qsub -b y -V -cwd -N collate Rscript scripts/collateRunFinalParameters.2016-11-14.R



# testing parallel score vec on dpsf

qsub -V -b y -cwd -N psf16test -pe smp.pe 16 Rscript scripts/mus.x-inactivationModel.parallel.16.R
# supposed to be a 20 minute job, first attempt with 16 cores still running after 2 days!

# try with same number of cores but fewer parallel jobs.


qsub -V -b y -cwd -N psf4test -pe smp.pe 16 Rscript scripts/mus.x-inactivationModel.parallel.4.R
qsub -V -b y -cwd -N psf6test -pe smp.pe 16 Rscript scripts/mus.x-inactivationModel.parallel.6.R
qsub -V -b y -cwd -N psf8test -pe smp.pe 16 Rscript scripts/mus.x-inactivationModel.parallel.8.R
qsub -V -b y -cwd -N psf10test -pe smp.pe 16 Rscript scripts/mus.x-inactivationModel.parallel.10.R
qsub -V -b y -cwd -N psf12test -pe smp.pe 16 Rscript scripts/mus.x-inactivationModel.parallel.12.R
qsub -V -b y -cwd -N psf16test -pe smp.pe 16 Rscript scripts/mus.x-inactivationModel.parallel.16.R
# 4 jobs
#	cores	t.1	t.2	t.3
# 	4	196	hung	189
#	6	hung	242	194
#	8	hung	hung	199
#	10	259	266	336
#	12	210	hung	212
#	16	hung	592	220




job-ID  prior   name       user         state submit/start at     queue                          slots ja-task-ID
-----------------------------------------------------------------------------------------------------------------
  45603 11.00000 psf4test   mqbssdgb     r     11/21/2016 09:52:01 C6320-256.q@node122.prv.hydra.    16
  45604 11.00000 psf6test   mqbssdgb     r     11/21/2016 09:52:01 C6320-256.q@node128.prv.hydra.    16
  45605 11.00000 psf8test   mqbssdgb     r     11/21/2016 09:52:01 C6320-256.q@node129.prv.hydra.    16
  45606 11.00000 psf10test  mqbssdgb     r     11/21/2016 09:52:02 C6320-256.q@node119.prv.hydra.    16
  45607 11.00000 psf12test  mqbssdgb     r     11/21/2016 09:52:02 C6320-256.q@node110.prv.hydra.    16
  45608 3.19512 psf16test  mqbssdgb     r     11/21/2016 09:52:03 C6320-256.q@node108.prv.hydra.    16



results of successful n=16 run:

	more ../q_out/psf16test.o45608


Some days later, I ran the above scripts again. They all worked (column t.3)


Need to take the parallelisation code in scripts/mus.x-inactivationModel.parallel.16.R and create a new batch optimisation script with associated CONFIG

new script:  scripts/mus.x-inactivationModel.BatchOpt.parallel.fromConfig.R
new CONFIG:  scripts/CONFIG.mus.x-inactivationModel.BatchOpt.2016-11-25.dpsf.R

Any need to retain waveList?  seems a waste of memory and resources.

test it once:


	module load libs/bioconductor/3.3/gcc-4.8.5+R-3.3.1
	qsub -pe smp.pe 16 -cwd -V -N BachOptTest -b y  Rscript $SCRATCH/predictfromsequence/scripts/mus.x-inactivationModel.BatchOpt.parallel.fromConfig.R --config scripts/CONFIG.mus.x-inactivationModel.BatchOpt.2016-11-25.dpsf.R --job_id 9999

Once that is working, set of a batch job. How many?  50, 100?

	 qsub -V -N batch -cwd ./scripts/mus.x.batchOpt.2016-11-25.submitter.sh

Array of 100 but reduced the number of optimisation rounds to 100 for each.


After 20/100 had completed, quite modest increases. e.g. 0.46 to 0.49.

Probably should be using some form of t-test to compare new runs.

	 qsub -V -N batch -cwd ./scripts/mus.x.batchOpt.2016-11-26.submitter.sh


Most runs saw ONE improvement (in 100 rounds). Some saw two

	 grep 'Wilcox p-value:  0.0'  ../q_out/batch.o47015.*

This one had two

	 grep -C 6 'Wilcox p-value:  0.0'  ../q_out/batch.o47015.22




